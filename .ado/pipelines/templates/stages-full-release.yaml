parameters:
  - name: environment
    type: string
  - name: runLoadTesting # embedded load testing
    type: boolean
    default: false
  - name: runChaosTesting # Chaos testing
    type: boolean
    default: false
  - name: destroyOldEnvironment
    type: boolean
    default: true
  - name: trafficSwitchSteps # in which steps (weights) the gradual traffic switch in Front Door should happen
    type: object
    default:
    - 10
    - 50
    - 100

stages:

- stage: deployglobalinfrastructure
  displayName: 'Deploy Global Infrastructure' # Deploy Global Azure Infrastructure
  jobs:

  - deployment: deployterraformglobalresources
    displayName: 'Deploy Terraform Global Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    environment: '$(environment)'
    strategy:
      runOnce:
        deploy:
          steps:
          - checkout: self # checkout github repository

          - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

          # Check if terraform state store exists, and create it if not
          - template: steps-terraform-setup-statestore.yaml
            parameters:
              storageAccountName: '$(terraformStorageAccount)'
              resourceGroupName: '$(terraformResourceGroup)'

          # Global Resources terraform init
          - template: steps-terraform-init.yaml # Initialize Terraform
            parameters:
              terraformStorageAccountName:       '$(terraformStorageAccount)'
              terraformStorageResourceGroupName: '$(terraformResourceGroup)'
              terraformStateFilename:            '$(terraformStateFileGlobal)'
              terraformWorkingDirectory:         '$(workingDirectory)/globalresources'

          - task: AzureCLI@2
            displayName: 'Fetch current Front Door backends'
            retryCountOnTaskFailure: 1
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              scriptType: pscore
              scriptLocation: inlineScript
              inlineScript: |
                # We need the az CLI Front Door extension
                az extension add --name front-door

                $rgName = "$(prefix)$(globalSuffix)-global-rg"
                $fdName = "$(prefix)$(globalSuffix)-global-fd"

                # check if Front Door exists
                $frontDoor = $(az network front-door list --query "[?name=='$fdName']" -o tsv)

                if($LastExitCode -ne 0)
                {
                    throw "*** Error on checking existing Front Door $fdName"
                }

                $backendPools = @("BackendApis", "StaticStorage")

                if($frontDoor)
                {
                  foreach($pool in $backendPools)
                  {
                    $backends = $(az network front-door backend-pool backend list `
                                    --front-door-name $fdName `
                                    --pool-name $pool -g $rgName `
                                    --query "[].{address:address,weight:weight,enabled:enabledState}")

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool $pool"
                    }

                    $jsonBackends = $backends | ConvertFrom-Json -NoEnumerate
                    # Rewrite EnabledState into bool (true/false)
                    foreach($backend in $jsonBackends)
                    {
                      if($backend.enabled -eq "Enabled")
                      {
                        $backend.enabled = "true"
                      }
                      else
                      {
                        $backend.enabled = "false"
                      }
                    }

                    $flatJsonApis = $jsonBackends | ConvertTo-Json -Compress -Depth 100 -AsArray
                    echo "*** Current backends in pool $($pool): " $flatJsonApis
                    $contentBackends = "-var='backends_$pool=$flatJsonApis'"

                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]$contentBackends"
                  }
                }
                else
                {
                  echo "*** Front Door $fdName does not exist. Using dummy backends from TF variable defaults"

                  # Writing empty ADO variables for each backend pool
                  foreach($pool in $backendPools)
                  {
                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]"
                  }
                }

          # Global Resources deployment
          - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
            parameters:
              jobName:                    'GlobalInfra'
              terraformWorkingDirectory:  '$(workingDirectory)/globalresources'
              customPrefix:               '$(prefix)$(globalSuffix)'      # custom resource prefix
              customAttributes:           '-var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          $(tfParameterFrontDoorBackendApis)
                                          $(tfParameterFrontDoorStaticStorage)
                                          $(terraformAdditionalParametersCustomDomains)'

- stage: deployreleaseinfrastructure
  displayName: 'Deploy Release Unit Infrastructure' # Deploy Release Unit Azure Infrastructure
  dependsOn: deployglobalinfrastructure
  jobs:
  - job: deployterraform
    displayName: 'Deploy Terraform Release Unit Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    steps:
    - checkout: self # checkout github repository
    - download: current # download pipeline artifacts

    - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

    - template: steps-parse-terraform-output.yaml
      parameters:
        workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory

    # Release Unit Resources terraform init
    - template: steps-terraform-init.yaml
      parameters:
        terraformStorageAccountName:        '$(terraformStorageAccount)'
        terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
        terraformStateFilename:             '$(terraformStateFileReleaseUnit)'
        terraformWorkingDirectory:          '$(workingDirectory)/releaseunit'

    # Release Unit Resources deployment
    - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
      parameters:
        jobName:                    'ReleaseUnitInfra'
        terraformWorkingDirectory:  '$(workingDirectory)/releaseunit'
        customPrefix:               '$(prefix)$(customSuffix)'
        customAttributes:           '-var=branch="$(sourceBranch)"
                                    -var=queued_by="$(Build.QueuedBy)"
                                    -var=contact_email="$(contactEmail)"
                                    -var=''stamps=$(stampLocations)''
                                    -var=kubernetes_version="$(kubernetesVersion)"
                                    -var=global_resource_group_name="$(global_resource_group_name)"
                                    -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                    -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                    -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                    -var=acr_name="$(acr_name)"
                                    -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                    -var=frontdoor_name="$(frontdoor_name)"
                                    -var=frontdoor_id_header="$(frontdoor_id_header)"
                                    -var=global_storage_account_name="$(global_storage_account_name)"
                                    -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

- stage: deployconfiguration
  displayName: 'Deploy Configuration' # Apply configuration to Azure Infrastructure
  dependsOn: deployreleaseinfrastructure
  jobs:
  - template: jobs-configuration.yaml
    parameters:
      runChaosTesting: ${{ parameters.runChaosTesting }}

- stage: testcode
  displayName: 'Test Application Code'
  dependsOn: [] # can run in parallel to the global infra deployment at the very start
  jobs:
  - template: jobs-code-tests.yaml
    parameters:
      jobName:          'CodeTests'
      workingDirectory: 'src/app'

- stage: buildapplication
  displayName: 'Build Application Code'
  dependsOn:
   - testcode
   - deployglobalinfrastructure # requires the global infra to be deployed which contains the Container Registry
  jobs: # using jobs so they each runs in parallel

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'catalogservice' # unique pipeline job name
      containerImageName:       '$(catalogserviceImageName)'  # container image name for CatalogService
      containerImageDockerFile: '$(catalogserviceDockerfile)' # dockerfile used to build the CatalogService

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'backgroundprocessor' # unique pipeline job name
      containerImageName:       '$(backgroundprocessorImageName)'   # container image name for BackgroundProcessor
      containerImageDockerFile: '$(backgroundprocessorDockerfile)'  # dockerfile used to build the BackgroundProcessor

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'healthservice' # unique pipeline job name
      containerImageName:       '$(healthserviceImageName)'  # container image name for healthservice
      containerImageDockerFile: '$(healthserviceDockerfile)' # dockerfile used to build the healthservice

  - template: jobs-ui-app-build.yaml
    parameters:
      jobName:          'buildui'
      workingDirectory: 'src/app/AlwaysOn.UI'

- stage: deployworkload # Deploy workload to previously created infrastructure
  displayName: 'Deploy Workload'
  dependsOn:
  - deployconfiguration
  - testcode
  - buildapplication
  jobs:
  - template: jobs-workload-deploy.yaml

- stage: importSampleData # Import sample data
  displayName: 'Import sample data'
  dependsOn: deployworkload
  jobs:
  - template: jobs-init-sampledata.yaml

- stage: testingOnlyStampEndpoints # smoke-testing the stamp endpoints
  displayName: 'Testing Stamp Endpoints'
  dependsOn: importSampleData
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: true
      testGlobalEndpoint: false

- ${{ each step in parameters.trafficSwitchSteps }}: # based on the list parameter trafficSwitchSteps this step will be repeated n number of times
  - template: stages-configure-frontdoor.yaml
    parameters:
      trafficWeightNewBackends: ${{ step }}

- stage: testingGlobalEndpoints # smoke-testing global endpoint only after the switchover has happened
  displayName: 'Testing Global Endpoint'
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: false
      testGlobalEndpoint: true

# headless load testing for e2e (optional) with locust. Runs if either Load test or Chaos test was selected by the user
- ${{ if and(eq(parameters.environment, 'e2e'), or(eq(parameters.runLoadTesting, 'true'), eq(parameters.runChaosTesting, 'true'))) }}: # only in e2e and when either runLoadTesting or runChaosTesting is true
  - template: stages-locust.yaml # headless load testing
    parameters:
      terraformWorkingDirectory: 'src/testing/loadtest-locust/infra'
      customPrefix: '$(prefix)$(customSuffix)'
      loadTestNumberOfWorkerNodes: $(loadTestNumberOfWorkerNodes)
      loadTestDurationInSeconds: $(loadTestDurationInSeconds)
      loadTestNumberOfUsers: $(loadTestNumberOfUsers)
      loadTestUserSpawnRate: $(loadTestUserSpawnRate)
      locustHeadless: true # run locust in headless mode

# Chaos testing for e2e (optional) with Azure Chaos Studio
- ${{ if and(eq(parameters.environment, 'e2e'), eq(parameters.runChaosTesting, 'true')) }}: # only in e2e and when runChaosTesting is true
  - template: stages-chaos.yaml # chaos testing pipline
    parameters:
      stageName: 'deployChaosExperiments'
      customPrefix: '$(prefix)$(customSuffix)'
      testDurationSeconds: 180 # Chaos test duration for each experiment
      memoryStress: true # run Chaos Memory stress
      cpuStress: true # run Chaos CPU stress
      podKiller: true # run Chaos Pod Killer
      dependsOn:
      - testingGlobalEndpoints

- ${{ if eq(parameters.destroyOldEnvironment, 'true') }}: # Only for E2E the user could have manually chosen not to destroy the environment
  - stage: destroyOldInfrastructure                # In E2E this will destroy the infrastructure that was deployed from the same branch. For int/prod, this will fetch the previous release infra and destroy that
    displayName: 'Destroy Infrastructure'
    jobs:
    - deployment: 'destroyOldReleaseStampsJob' # Using a deployment job so that we can have manual approves, which are configured on the environment specificed below
      displayName: 'Destroy Old Release Unit Deployment'
      timeoutInMinutes: 120 # extend the default timeout of 60min since destroy can take a while
      environment: '$(environment)'
      strategy:
        runOnce:
          deploy:
            steps:

            - checkout: self # checkout github repository

            - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

            - template: steps-buildagent-prerequisites.yaml # Install tools like kubectl

            - ${{ if ne(parameters.environment, 'e2e') }}: # Only in int/prod
              - task: AzureCLI@2
                displayName: 'Fetch previous release prefix through disabled Front Door backends'
                retryCountOnTaskFailure: 1
                inputs:
                  azureSubscription: '$(azureServiceConnection)'
                  scriptType: pscore
                  scriptLocation: inlineScript
                  inlineScript: |
                    # We need the az CLI Front Door extension
                    az extension add --name front-door

                    $globalInfraDeployOutput = Get-ChildItem $(Pipeline.Workspace)/terraformOutputGlobalInfra/*.json | Get-Content | ConvertFrom-JSON

                    $rgName = $globalInfraDeployOutput.global_resource_group_name.value
                    $fdName = $globalInfraDeployOutput.frontdoor_name.value

                    # Fetch disabled backends from the BackendApis pool. We only fetch the first one, assuming it represents all the stamps of the previous release unit
                    $disabledBackendAddress = $(az network front-door backend-pool backend list `
                                      --front-door-name $fdName `
                                      --pool-name BackendApis `
                                      --resource-group $rgName `
                                      --query "[?enabledState=='Disabled'].{address:address}[0]" -o tsv)

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool 'BackendApis'. Make sure the backend pool exists!"
                    }

                    $prefix = ""
                    # Only valid if we found any disabled backend (=an old release unit)
                    if($disabledBackendAddress)
                    {
                      echo "*** Found disabled backend $disabledBackendAddress"

                      # Lookup the Public IP resource for this FQDN and fetch the Prefix tag from it
                      $prefix = az network public-ip list --query "[?dnsSettings.fqdn == '$disabledBackendAddress'].{prefix:tags.Prefix}" -o tsv

                      if(-not $prefix)
                      {
                        throw "*** No Public IP found (or not Prefix tag) for FQDN $disabledBackendAddress"
                      }

                      echo "*** Found prefix tag $prefix"
                    }

                    if((-not $disabledBackendAddress) -or ($prefix -eq ""))
                    {
                      # This can happen on the very first run of the INT or PROD pipeline. We'll set the prefix to some dummy. Terraform destroy will be happy but has nothing to really destroy
                      Write-Warning "*** No disabled backends found or prefix empty. Nothing to destroy."

                      $prefix = "DUMMYPRE"
                    }

                    echo "##vso[task.setvariable variable=oldReleasePrefix]$prefix" # set pipeline variable

            - ${{ if eq(parameters.environment, 'e2e') }}: # Special case for E2E only
              - task: PowerShell@2
                displayName: '(E2E-only) Set oldReleasePrefix to prefix-customSuffix'
                inputs:
                  targetType: inline
                  script: |
                    # Setting oldReleasePrefix=prefix-customSuffix means that we target the same release unit that was deployed earlier by this very pipeline
                    echo "*** Setting pipeline variable oldReleasePrefix = $(prefix)$(customSuffix)"
                    echo "##vso[task.setvariable variable=oldReleasePrefix]$(prefix)$(customSuffix)"

            - template: steps-parse-terraform-output.yaml
              parameters:
                workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory


            # Delete all deployments in the workload namespace. This will make sure the application is not running anymore before we destroy the infrastructure in the next step.
            # This prevents side effects in the logging in which errors might show up which are only related to the destructions of the infra
            - task: AzureCLI@2
              displayName: 'Delete application deployments on AKS prior to destroy'
              retryCountOnTaskFailure: 1
              inputs:
                azureSubscription: $(azureServiceConnection)
                scriptType: pscore
                scriptLocation: inlineScript
                inlineScript: |

                  # Find AKS clusters with the prefix $(oldReleasePrefix)
                  $aksClusters = az resource list --tag prefix="$(oldReleasePrefix)" --query "[?type == 'Microsoft.ContainerService/managedClusters']" | ConvertFrom-Json

                  echo "*** Found $($aksClusters.Count) AKS cluster(s) for prefix $(oldReleasePrefix)"

                  # loop through all clusters
                  foreach($cluster in $aksClusters) {

                    $aksClusterName = $cluster.name
                    $aksClusterResourceGroup = $cluster.resourceGroup

                    echo "*** Load credentials for AKS Cluster $aksClusterName in $aksClusterResourceGroup"
                    az aks get-credentials --name $aksClusterName --resource-group $aksClusterResourceGroup --overwrite-existing

                    echo "*** Deleting all deployments in namespace $(workloadNamespace)"
                    kubectl delete --all deployments --namespace=$(workloadNamespace)
                  }

            # Initialize Terraform for destroy
            - template: steps-terraform-destroy.yaml
              parameters:
                terraformStorageAccountName:       '$(terraformStorageAccount)'
                terraformStorageResourceGroupName: '$(terraformResourceGroup)'
                terraformStateFilename:            'terraform-$(oldReleasePrefix).state'
                terraformWorkingDirectory:         '$(workingDirectory)/releaseunit'
                customAttributes:        '-var=prefix="$(oldReleasePrefix)"
                                          -var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          -var=kubernetes_version="$(kubernetesVersion)"
                                          -var=global_resource_group_name="$(global_resource_group_name)"
                                          -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                          -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                          -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                          -var=acr_name="$(acr_name)"
                                          -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                          -var=frontdoor_name="$(frontdoor_name)"
                                          -var=frontdoor_id_header="$(frontdoor_id_header)"
                                          -var=global_storage_account_name="$(global_storage_account_name)"
                                          -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

            # Remove disabled backends from Front Door and reset weight on current ones to 50. (Not required for E2E since we destroy E2E Front Door anyway below)
            - ${{ if ne(parameters.environment, 'e2e') }}:
              - template: steps-frontdoor-traffic-switch.yaml
                parameters:
                  trafficWeightNewBackends: 50
                  removeDisabledBackends: true

    - ${{ if eq(parameters.environment, 'e2e') }}: # Only happens in E2E
      - deployment: 'destroyE2EGlobalResourcesJob'  # Destroy globally shared resources for this E2E env
        displayName: 'Destroy E2E Global Resources'
        timeoutInMinutes: 120 # extend the default timeout of 60min since destroy can take a while
        environment: '$(environment)'
        dependsOn: 'destroyOldReleaseStampsJob'
        strategy:
          runOnce:
            deploy:
              steps:

              - checkout: self # checkout github repository

              - download: current # download pipeline artifacts

              - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

              # Initialize Terraform for destroy
              - template: steps-terraform-destroy.yaml
                parameters:
                  terraformStorageAccountName:        '$(terraformStorageAccount)'
                  terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
                  terraformStateFilename:             '$(terraformStateFileGlobal)'
                  terraformWorkingDirectory:          '$(workingDirectory)/globalresources'
                  customAttributes:           '-var=prefix="$(prefix)$(globalSuffix)"
                                               -var=environment="${{ parameters.environment }}"
                                               -var=branch="$(sourceBranch)"
                                               -var=queued_by="$(Build.QueuedBy)"
                                               -var=contact_email="$(contactEmail)"
                                               -var=''stamps=$(stampLocations)''
                                               $(terraformAdditionalParametersCustomDomains)'
