parameters:
  - name: environment # target environment (e2e, int or prod)
    type: string

  - name: runEmbeddedLoadtesting # Enable or disable embedded load testing
    type: boolean
    default: false

  - name: runChaosTesting # Enable or disable embedded Chaos testing (automatically enables load testing)
    type: boolean
    default: false

  - name: destroyOldEnvironment # select whether or not to destroy the environment at the end
    type: boolean
    default: true

  - name: trafficSwitchSteps # in which steps (weights) the gradual traffic switch in Front Door should happen
    type: object
    default:
    - 10
    - 50
    - 100

stages:

- stage: deployglobalinfrastructure
  displayName: 'Deploy Global Infrastructure'
  jobs:

  - deployment: deployterraformglobalresources
    displayName: 'Deploy Terraform Global Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    environment: '$(environment)'
    strategy:
      runOnce:
        deploy:
          steps:
          - checkout: self # checkout github repository

          - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

          # Check if terraform state store exists, and create it if not
          - template: steps-terraform-setup-statestore.yaml
            parameters:
              storageAccountName: '$(terraformStorageAccount)'
              resourceGroupName: '$(terraformResourceGroup)'

          # Global Resources terraform init
          - template: steps-terraform-init.yaml # Initialize Terraform
            parameters:
              terraformStorageAccountName:       '$(terraformStorageAccount)'
              terraformStorageResourceGroupName: '$(terraformResourceGroup)'
              terraformStateFilename:            '$(terraformStateFileGlobal)'
              terraformWorkingDirectory:         '$(workingDirectory)/globalresources'

          - task: AzureCLI@2
            displayName: 'Fetch current Front Door backends'
            retryCountOnTaskFailure: 1
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              scriptType: pscore
              scriptLocation: inlineScript
              inlineScript: |
                # We need the az CLI Front Door extension
                az extension add --name front-door

                $rgName = "$(prefix)$(globalResourceSuffix)-global-rg"
                $fdName = "$(prefix)$(globalResourceSuffix)-global-fd"

                # check if Front Door exists
                $frontDoor = $(az network front-door list --query "[?name=='$fdName']" -o tsv)

                if($LastExitCode -ne 0)
                {
                    throw "*** Error on checking existing Front Door $fdName"
                }

                $backendPools = @("BackendApis", "StaticStorage")

                if($frontDoor)
                {
                  foreach($pool in $backendPools)
                  {
                    $backends = $(az network front-door backend-pool backend list `
                                    --front-door-name $fdName `
                                    --pool-name $pool -g $rgName `
                                    --query "[].{address:address,weight:weight,enabled:enabledState}")

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool $pool"
                    }

                    $jsonBackends = $backends | ConvertFrom-Json -NoEnumerate
                    # Rewrite EnabledState into bool (true/false)
                    foreach($backend in $jsonBackends)
                    {
                      if($backend.enabled -eq "Enabled")
                      {
                        $backend.enabled = "true"
                      }
                      else
                      {
                        $backend.enabled = "false"
                      }
                    }

                    $flatJsonApis = $jsonBackends | ConvertTo-Json -Compress -Depth 100 -AsArray
                    echo "*** Current backends in pool $($pool): " $flatJsonApis
                    $contentBackends = "-var='backends_$pool=$flatJsonApis'"

                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]$contentBackends"
                  }
                }
                else
                {
                  echo "*** Front Door $fdName does not exist. Using dummy backends from TF variable defaults"

                  # Writing empty ADO variables for each backend pool
                  foreach($pool in $backendPools)
                  {
                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]"
                  }
                }

          # Global Resources deployment
          - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
            parameters:
              jobName:                    'GlobalInfra'
              terraformWorkingDirectory:  '$(workingDirectory)/globalresources'
              customPrefix:               '$(prefix)$(globalResourceSuffix)'      # custom resource prefix
              customAttributes:           '-var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          $(tfParameterFrontDoorBackendApis)
                                          $(tfParameterFrontDoorStaticStorage)
                                          $(terraformAdditionalParametersCustomDomains)'

- stage: deployreleaseinfrastructure
  displayName: 'Deploy Release Unit Infrastructure' # Deploy Release Unit Azure Infrastructure
  dependsOn: deployglobalinfrastructure
  jobs:
  - job: deployterraform
    displayName: 'Deploy Terraform Release Unit Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    steps:
    - checkout: self # checkout github repository
    - download: current # download pipeline artifacts

    - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

    - template: steps-parse-terraform-output.yaml
      parameters:
        workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory

    # Release Unit Resources terraform init
    - template: steps-terraform-init.yaml
      parameters:
        terraformStorageAccountName:        '$(terraformStorageAccount)'
        terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
        terraformStateFilename:             '$(terraformStateFileReleaseUnit)'
        terraformWorkingDirectory:          '$(workingDirectory)/releaseunit'

    # Release Unit Resources deployment
    - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
      parameters:
        jobName:                    'ReleaseUnitInfra'
        terraformWorkingDirectory:  '$(workingDirectory)/releaseunit'
        customPrefix:               '$(prefix)$(customSuffix)'
        customAttributes:           '-var=branch="$(sourceBranch)"
                                    -var=queued_by="$(Build.QueuedBy)"
                                    -var=contact_email="$(contactEmail)"
                                    -var=''stamps=$(stampLocations)''
                                    -var=aks_kubernetes_version="$(kubernetesVersion)"
                                    -var=global_resource_group_name="$(global_resource_group_name)"
                                    -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                    -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                    -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                    -var=acr_name="$(acr_name)"
                                    -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                    -var=frontdoor_name="$(frontdoor_name)"
                                    -var=frontdoor_id_header="$(frontdoor_id_header)"
                                    -var=global_storage_account_name="$(global_storage_account_name)"
                                    -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

- stage: deployconfiguration
  displayName: 'Deploy Configuration' # Apply configuration to Azure Infrastructure
  dependsOn: deployreleaseinfrastructure
  jobs:
  - template: jobs-deploy-configuration.yaml
    parameters:
      prepareForChaosTesting: ${{ parameters.runChaosTesting }}

- stage: testcode
  displayName: 'Test Application Code'
  dependsOn: [] # can run in parallel to the global infra deployment at the very start
  jobs:
  - template: jobs-code-tests.yaml
    parameters:
      jobName:          'CodeTests'
      workingDirectory: 'src/app'

- stage: buildapplication
  displayName: 'Build Application Code'
  dependsOn:
   - testcode
   - deployglobalinfrastructure # requires the global infra to be deployed which contains the Container Registry
  jobs: # using jobs so they each runs in parallel

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'catalogservice' # unique pipeline job name
      containerImageName:       '$(catalogserviceImageName)'  # container image name for CatalogService
      containerImageDockerFile: '$(catalogserviceDockerfile)' # dockerfile used to build the CatalogService

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'backgroundprocessor' # unique pipeline job name
      containerImageName:       '$(backgroundprocessorImageName)'   # container image name for BackgroundProcessor
      containerImageDockerFile: '$(backgroundprocessorDockerfile)'  # dockerfile used to build the BackgroundProcessor

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'healthservice' # unique pipeline job name
      containerImageName:       '$(healthserviceImageName)'  # container image name for healthservice
      containerImageDockerFile: '$(healthserviceDockerfile)' # dockerfile used to build the healthservice

  - template: jobs-ui-app-build.yaml
    parameters:
      jobName:          'buildui'
      workingDirectory: 'src/app/AlwaysOn.UI'

- stage: deployworkload # Deploy workload to previously created infrastructure
  displayName: 'Deploy Workload'
  dependsOn:
  - deployconfiguration
  - testcode
  - buildapplication
  jobs:
  - template: jobs-deploy-workload.yaml

- stage: importSampleData # Import sample data
  displayName: 'Import sample data'
  dependsOn: deployworkload
  jobs:
  - template: jobs-init-sampledata.yaml

- stage: testingOnlyStampEndpoints # smoke-testing the stamp endpoints
  displayName: 'Test Stamp Endpoints'
  dependsOn: importSampleData
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: true
      testGlobalEndpoint: false

- ${{ each step in parameters.trafficSwitchSteps }}: # based on the list parameter trafficSwitchSteps this step will be repeated n number of times
  - template: stages-configure-frontdoor.yaml
    parameters:
      trafficWeightNewBackends: ${{ step }}

- stage: testingGlobalEndpoints # smoke-testing global endpoint only after the switchover has happened
  displayName: 'Test Global Endpoint'
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: false
      testGlobalEndpoint: true

- ${{ if eq(parameters.environment, 'e2e') }}:
  # Pipeline-embedded load testing for e2e (optional) with Microsoft Azure Load Test (MALT).
  # Runs if either Load test or Chaos test was selected by the user
  - ${{ if or(eq(parameters.runEmbeddedLoadtesting, 'true'), eq(parameters.runChaosTesting, 'true')) }}: # only in e2e and when either runLoadTesting or runChaosTesting is true
    - template: stages-loadtest-azure.yaml # embedded load testing
      parameters:
        terraformWorkingDirectory: 'src/testing/loadtest-azure/infra'
        customPrefix: '$(prefix)$(customSuffix)'
        destroyInfra: ${{ parameters.destroyOldEnvironment }} # this will destroy the load test infrastructure together with the other infrastructure
        runChaosTesting: ${{ parameters.runChaosTesting }} # handover chaos parameter to let the load test know if chaos is running or not
        embeddedLoadTest: true # execute loadtest pipeline-embedded aka headless

  # Chaos testing for e2e (optional) with Azure Chaos Studio
  - ${{ if eq(parameters.runChaosTesting, 'true') }}: # only in e2e and when runChaosTesting is true
    - template: stages-chaos.yaml # chaos testing pipeline
      parameters:
        stageName: 'deployChaosExperiments'
        customPrefix: '$(prefix)$(customSuffix)'
        experimentDurationSeconds: '$(chaosExperimentDurationSeconds)' # duration of each experiment
        startDelaySeconds: '$(chaosStartDelaySeconds)'
        podFailure: true # run Chaos Pod Failure experiment
        memoryStress: false # do not run Chaos Memory stress
        cpuStress: false # do not run Chaos CPU stress
        dependsOn:
        - testingGlobalEndpoints

- ${{ if eq(parameters.destroyOldEnvironment, 'true') }}: # Only for E2E the user could have manually chosen not to destroy the environment
  - stage: destroyOldInfrastructure # In E2E this will destroy the infrastructure that was deployed from the same branch. For int/prod, this will fetch the previous release infra and destroy that
    displayName: 'Destroy Infrastructure'
    jobs:
    - deployment: 'destroyOldReleaseStampsJob' # Using a deployment job so that we can have manual approves, which are configured on the environment specificed below
      displayName: 'Destroy Old Release Unit Deployment'
      timeoutInMinutes: 120 # extend the default timeout of 60min since destroy can take a while
      environment: '$(environment)'
      strategy:
        runOnce:
          deploy:
            steps:

            - checkout: self # checkout github repository

            - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

            - template: steps-buildagent-prerequisites.yaml # Install tools like kubectl

            - template: steps-parse-terraform-output.yaml # parse global configuration settings from terraform deployment output
              parameters:
                workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory

            - ${{ if ne(parameters.environment, 'e2e') }}: # Only in int/prod
              - task: AzureCLI@2
                displayName: 'Fetch previous release prefix through disabled Front Door backends'
                retryCountOnTaskFailure: 1
                inputs:
                  azureSubscription: '$(azureServiceConnection)'
                  scriptType: pscore
                  scriptLocation: inlineScript
                  inlineScript: |
                    # We need the az CLI Front Door extension
                    az extension add --name front-door

                    # Fetch disabled backends from the BackendApis pool. We only fetch the first one, assuming it represents all the stamps of the previous release unit
                    $disabledBackendAddress = $(az network front-door backend-pool backend list `
                                      --front-door-name $(frontdoor_name) `
                                      --pool-name BackendApis `
                                      --resource-group $(global_resource_group_name) `
                                      --query "[?enabledState=='Disabled'].{address:address}[0]" -o tsv)

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool 'BackendApis'. Make sure the backend pool exists!"
                    }

                    $prefix = ""
                    # Only valid if we found any disabled backend (=an old release unit)
                    if($disabledBackendAddress)
                    {
                      echo "*** Found disabled backend $disabledBackendAddress"

                      # Lookup the Public IP resource for this FQDN and fetch the Prefix tag from it
                      $prefix = az network public-ip list --query "[?dnsSettings.fqdn == '$disabledBackendAddress'].{prefix:tags.Prefix}" -o tsv

                      if(-not $prefix)
                      {
                        throw "*** No Public IP found (or not Prefix tag) for FQDN $disabledBackendAddress"
                      }

                      echo "*** Found prefix tag $prefix"
                    }

                    if((-not $disabledBackendAddress) -or ($prefix -eq ""))
                    {
                      # This can happen on the very first run of the INT or PROD pipeline. We'll set the prefix to some dummy. Terraform destroy will be happy but has nothing to really destroy
                      Write-Warning "*** No disabled backends found or prefix empty. Nothing to destroy."

                      $prefix = "DUMMYPRE"
                    }

                    echo "##vso[task.setvariable variable=oldReleasePrefix]$prefix" # set pipeline variable

            - ${{ if eq(parameters.environment, 'e2e') }}: # Special case for E2E only
              - task: PowerShell@2
                displayName: '(E2E-only) Set oldReleasePrefix to prefix-customSuffix'
                inputs:
                  targetType: inline
                  script: |
                    # Setting oldReleasePrefix=prefix-customSuffix means that we target the same release unit that was deployed earlier by this very pipeline
                    echo "*** Setting pipeline variable oldReleasePrefix = $(prefix)$(customSuffix)"
                    echo "##vso[task.setvariable variable=oldReleasePrefix]$(prefix)$(customSuffix)"

            # Delete all deployments in the workload namespace. This will make sure the application is not running anymore before we destroy the infrastructure in the next step.
            # This prevents side effects in the logging in which errors might show up which are only related to the destructions of the infra
            - task: AzureCLI@2
              displayName: 'Delete application deployments on AKS prior to destroy'
              retryCountOnTaskFailure: 1
              inputs:
                azureSubscription: $(azureServiceConnection)
                scriptType: pscore
                scriptLocation: inlineScript
                inlineScript: |

                  # Find AKS clusters with the prefix $(oldReleasePrefix)
                  $aksClusters = az aks list --query "[?tags.Prefix=='$(oldReleasePrefix)']" | ConvertFrom-Json

                  echo "*** Found $($aksClusters.Count) AKS cluster(s) for prefix $(oldReleasePrefix)"

                  # loop through all clusters
                  foreach($cluster in $aksClusters) {

                    $aksClusterName = $cluster.name
                    $aksClusterResourceGroup = $cluster.resourceGroup

                    echo "*** Load credentials for AKS Cluster $aksClusterName in $aksClusterResourceGroup"
                    az aks get-credentials --name $aksClusterName --resource-group $aksClusterResourceGroup --overwrite-existing

                    $ingressNamespace = "ingress-nginx"

                    # First delete the ingress controllers
                    echo "*** Deleting all deployments in namespace $ingressNamespace"
                    kubectl delete --all deployments --namespace=$ingressNamespace

                    # Now delete all the workload deployments
                    echo "*** Deleting all deployments in namespace $(workloadNamespace)"
                    kubectl delete --all deployments --namespace=$(workloadNamespace)
                  }

            # Initialize Terraform for destroy
            - template: steps-terraform-destroy.yaml
              parameters:
                terraformStorageAccountName:       '$(terraformStorageAccount)'
                terraformStorageResourceGroupName: '$(terraformResourceGroup)'
                terraformStateFilename:            'terraform-$(oldReleasePrefix).state'
                terraformWorkingDirectory:         '$(workingDirectory)/releaseunit'
                customAttributes:        '-var=prefix="$(oldReleasePrefix)"
                                          -var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          -var=aks_kubernetes_version="$(kubernetesVersion)"
                                          -var=global_resource_group_name="$(global_resource_group_name)"
                                          -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                          -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                          -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                          -var=acr_name="$(acr_name)"
                                          -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                          -var=frontdoor_name="$(frontdoor_name)"
                                          -var=frontdoor_id_header="$(frontdoor_id_header)"
                                          -var=global_storage_account_name="$(global_storage_account_name)"
                                          -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

            # Remove disabled backends from Front Door and reset weight on current ones to 50. (Not required for E2E since we destroy E2E Front Door anyway below)
            - ${{ if ne(parameters.environment, 'e2e') }}:
              - template: steps-frontdoor-traffic-switch.yaml
                parameters:
                  trafficWeightNewBackends: 50
                  removeDisabledBackends: true

    - ${{ if eq(parameters.environment, 'e2e') }}: # Only happens in E2E
      - deployment: 'destroyE2EGlobalResourcesJob'  # Destroy globally shared resources for this E2E env
        displayName: 'Destroy E2E Global Resources'
        timeoutInMinutes: 120 # extend the default timeout of 60min since destroy can take a while
        environment: '$(environment)'
        dependsOn: 'destroyOldReleaseStampsJob'
        strategy:
          runOnce:
            deploy:
              steps:

              - checkout: self # checkout github repository

              - download: current # download pipeline artifacts

              - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

              # Delete leftover Load Test resource (if still present)
              # There might be edge cases when load testing artifacts remain and need to be cleaned up
              - task: AzureCLI@2
                displayName: 'Cleanup leftover load testing artifacts (if needed)'
                retryCountOnTaskFailure: 1
                inputs:
                  azureSubscription: $(azureServiceConnection)
                  scriptType: pscore
                  scriptLocation: inlineScript
                  inlineScript: |
                    $loadtestRg = "$(prefix)$(customSuffix)-loadtest-rg"
                    $loadtestRgExists = az group exists --name $loadtestRg | ConvertFrom-Json
                    if ($loadtestRgExists) {
                      echo "*** Delete abandoned load test resources in $loadtestRg"
                      az group delete --name "$loadtestRg" --yes
                    } else {
                      echo "*** No load test resources found in $loadtestRg"
                    }

                    $ltTerraformStateFile = "terraform-azurelt-$(prefix)$(customSuffix).state"

                    $stateBlobExists = az storage blob exists --account-name $(terraformStorageAccount) `
                      --container-name tfstate `
                      --name $ltTerraformStateFile `
                      --auth-mode login -o tsv

                    if($stateBlobExists -eq "True")
                    {
                      echo "*** Deleting Terraform state file $ltTerraformStateFile on Storage Account $(terraformStorageAccount)"
                      az storage blob delete --account-name $(terraformStorageAccount) `
                        --container-name tfstate `
                        --name $ltTerraformStateFile `
                        --auth-mode login
                    }

              # Run Terraform for destroy for the global resources of this E2E env
              - template: steps-terraform-destroy.yaml
                parameters:
                  terraformStorageAccountName:        '$(terraformStorageAccount)'
                  terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
                  terraformStateFilename:             '$(terraformStateFileGlobal)'
                  terraformWorkingDirectory:          '$(workingDirectory)/globalresources'
                  customAttributes:           '-var=prefix="$(prefix)$(globalResourceSuffix)"
                                               -var=environment="${{ parameters.environment }}"
                                               -var=branch="$(sourceBranch)"
                                               -var=queued_by="$(Build.QueuedBy)"
                                               -var=contact_email="$(contactEmail)"
                                               -var=''stamps=$(stampLocations)''
                                               $(terraformAdditionalParametersCustomDomains)'
